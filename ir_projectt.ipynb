{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qDGo32chJ_b"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"jxie/flickr8k\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv ./flickr8k_images/Flicker8k_Dataset/* ./flickr8k_images/\n"
      ],
      "metadata": {
        "id": "ODCsiE76hezW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r ./flickr8k_images/Flicker8k_Dataset\n"
      ],
      "metadata": {
        "id": "vsGncy3Ihg59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Number of images:\", len(os.listdir('./flickr8k_images')))\n",
        "print(\"First 10 images:\", os.listdir('./flickr8k_images')[:10])\n"
      ],
      "metadata": {
        "id": "F_7ANdnOhkWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "captions_file = './flickr8k_text/Flickr8k.token.txt'\n",
        "\n",
        "image_captions = {}\n",
        "with open(captions_file, 'r') as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if len(line) == 0:\n",
        "            continue\n",
        "        img_cap, caption = line.split('\\t')\n",
        "        img_name = img_cap.split('#')[0]\n",
        "        if img_name not in image_captions:\n",
        "            image_captions[img_name] = []\n",
        "        image_captions[img_name].append(caption)\n",
        "\n",
        "list(image_captions.items())[:2]\n"
      ],
      "metadata": {
        "id": "2BJFqti2hlBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_caption(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    text = ' '.join([w for w in text.split() if w not in stop_words])\n",
        "    return text\n",
        "\n",
        "for img, caps in list(image_captions.items())[:5]:\n",
        "    image_captions[img] = [preprocess_caption(c) for c in caps]\n",
        "    print(img, image_captions[img])\n"
      ],
      "metadata": {
        "id": "U1DTfL2RhnW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "all_captions = [' '.join(caps) for caps in image_captions.values()]\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X_text = vectorizer.fit_transform(all_captions).toarray()\n",
        "\n",
        "print(\"TF-IDF feature shape:\", X_text.shape)\n"
      ],
      "metadata": {
        "id": "PPDeySGxhpzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
        "\n",
        "def get_image_features(img_path):\n",
        "    img = image.load_img(img_path, target_size=(224,224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    features = model.predict(x, verbose=0)\n",
        "    return features.flatten()\n",
        "\n",
        "image_files = list(image_captions.keys())[:100]\n",
        "X_image = np.array([get_image_features('./flickr8k_images/' + img) for img in image_files])\n",
        "print(\"Image feature shape:\", X_image.shape)\n"
      ],
      "metadata": {
        "id": "VqXX2wCEhsL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_text_subset = X_text[:len(image_files)]\n",
        "\n",
        "X_combined = np.hstack((X_text_subset, X_image))\n",
        "print(\"Combined feature shape:\", X_combined.shape)\n"
      ],
      "metadata": {
        "id": "IEX4tFYlhuqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "pca = PCA(n_components=50)\n",
        "X_reduced = pca.fit_transform(X_combined)\n",
        "\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "clusters = kmeans.fit_predict(X_reduced)\n",
        "\n",
        "print(\"Cluster labels for first 10 images:\", clusters[:10])\n"
      ],
      "metadata": {
        "id": "NraEaOY7hw2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "cluster_to_images = {}\n",
        "for img, label in zip(image_files, clusters):\n",
        "    if label not in cluster_to_images:\n",
        "        cluster_to_images[label] = []\n",
        "    cluster_to_images[label].append(img)\n",
        "\n",
        "for cluster_label, imgs in cluster_to_images.items():\n",
        "    print(f\"\\nCluster {cluster_label}:\")\n",
        "    sample_imgs = random.sample(imgs, min(5, len(imgs)))\n",
        "    plt.figure(figsize=(15,3))\n",
        "    for i, img_name in enumerate(sample_imgs):\n",
        "        img_path = './flickr8k_images/' + img_name\n",
        "        img = Image.open(img_path)\n",
        "        plt.subplot(1,5,i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title('\\n'.join(image_captions[img_name][:2]), fontsize=8)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "qLyw3AzShzMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import math\n",
        "\n",
        "images_per_cluster = 5\n",
        "cluster_labels = sorted(set(clusters))\n",
        "\n",
        "plt.figure(figsize=(20, len(cluster_labels)*4))\n",
        "\n",
        "for idx, cluster_label in enumerate(cluster_labels):\n",
        "\n",
        "    imgs_in_cluster = [img for img, lbl in zip(image_files, clusters) if lbl == cluster_label]\n",
        "\n",
        "    sample_imgs = imgs_in_cluster[:images_per_cluster]\n",
        "\n",
        "    for i, img_name in enumerate(sample_imgs):\n",
        "        plt_idx = idx*images_per_cluster + i + 1\n",
        "        plt.subplot(len(cluster_labels), images_per_cluster, plt_idx)\n",
        "        img_path = './flickr8k_images/' + img_name\n",
        "        img = Image.open(img_path)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title('\\n'.join(image_captions[img_name][:2]), fontsize=8)\n",
        "\n",
        "plt.suptitle(\"Flickr8k Image Clusters\", fontsize=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZNI9iWnvh1c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca_2d = PCA(n_components=2)\n",
        "X_2d = pca_2d.fit_transform(X_combined)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "for cluster_label in sorted(set(clusters)):\n",
        "    idxs = [i for i, lbl in enumerate(clusters) if lbl == cluster_label]\n",
        "    plt.scatter(X_2d[idxs, 0], X_2d[idxs, 1], label=f'Cluster {cluster_label}', alpha=0.6)\n",
        "\n",
        "plt.title(\"Scatter Plot of Image + Caption Clusters (2D)\")\n",
        "plt.xlabel(\"PCA Component 1\")\n",
        "plt.ylabel(\"PCA Component 2\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3qj9ecmkh31E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LFnFScB4h7hx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}